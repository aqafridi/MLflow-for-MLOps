{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2008fa7",
   "metadata": {},
   "source": [
    "# 1. Running and tracking machine learning experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36be61d6",
   "metadata": {},
   "source": [
    "## 1.0. The data we use: Palmer Pinguins\n",
    "\n",
    "Data were collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER, a member of the Long Term Ecological Research Network. It provides a great dataset for data exploration & visualization, as an alternative to iris.\n",
    "\n",
    "We will use this dataset in classification setting to predict the penguins’ species from anatomical information.\n",
    "\n",
    "Each penguin is from one of the three following species: Adelie, Gentoo, and Chinstrap.\n",
    "\n",
    "![palmer penguins](../resources/palmer_penguins.png \"Palmer Penguins\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706b6ce1",
   "metadata": {},
   "source": [
    "This problem is a classification problem since the target is categorical. We will use features based on penguins’ culmen measurement.\n",
    "\n",
    "![Culmen features](../resources/culmen_depth.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dee973",
   "metadata": {},
   "source": [
    "## 1.1. Load and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5501ff60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Culmen Length (mm)</th>\n",
       "      <th>Culmen Depth (mm)</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>46.8</td>\n",
       "      <td>14.3</td>\n",
       "      <td>Gentoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>39.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>Adelie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>51.7</td>\n",
       "      <td>20.3</td>\n",
       "      <td>Chinstrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>38.8</td>\n",
       "      <td>17.2</td>\n",
       "      <td>Adelie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>39.7</td>\n",
       "      <td>18.9</td>\n",
       "      <td>Adelie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Culmen Length (mm)  Culmen Depth (mm)    Species\n",
       "270                46.8               14.3     Gentoo\n",
       "144                39.0               18.7     Adelie\n",
       "285                51.7               20.3  Chinstrap\n",
       "23                 38.8               17.2     Adelie\n",
       "104                39.7               18.9     Adelie"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "target_column = \"Species\"\n",
    "\n",
    "data_path = \"penguins_classification.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "757404bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data, target = data[culmen_columns], data[target_column]\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b33dd0e",
   "metadata": {},
   "source": [
    "## 1.2. The modelling: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9daa4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, max_leaf_nodes=4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=3, max_leaf_nodes=4)\n",
    "tree.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55f76a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the DecisionTreeClassifier: 96.5%\n"
     ]
    }
   ],
   "source": [
    "test_score = tree.score(data_test, target_test)\n",
    "print(f\"Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3780fd",
   "metadata": {},
   "source": [
    "## 1.3. MLflow Stores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cded149",
   "metadata": {},
   "source": [
    "### Tracking stores\n",
    "\n",
    "MLflow supports two types of backend stores: file store and database-backed store.\n",
    "\n",
    "- Local file path (specified as file:/my/local/dir), where data is just directly stored locally. Defaults to `mlruns/`.\n",
    "- Database encoded as +://:<password>@:/. Mlflow supports the dialects mysql, mssql, sqlite, and postgresql. For more details, see SQLAlchemy database uri.\n",
    "- HTTP server (specified as https://my-server:5000), which is a server hosting an MLFlow tracking server.\n",
    "- Databricks workspace (specified as databricks or as databricks://, a Databricks CLI profile.)\n",
    "\n",
    "### Artifact stores\n",
    "Where you store models, plots and other stuff.\n",
    "\n",
    "- Amazon S3\n",
    "- Azure Blob Storage\n",
    "- Google Cloud Storage\n",
    "- FTP server\n",
    "- SFTP Server\n",
    "- NFS\n",
    "- HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98893984",
   "metadata": {},
   "source": [
    "## 1.4. Setup and configure the tracking server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150febdf",
   "metadata": {},
   "source": [
    "We want to use a database as a tracking store and a local directory as artifact store.\n",
    "Using a database is required for later steps in the tutorial, like managing deployments. In this case, artifacts are stored under the local ./mlruns directory, and MLflow entities are inserted in a SQLite database file mlruns.db.\n",
    "\n",
    "\n",
    "![tracking setup](../resources/tracking_setup.png)\n",
    "\n",
    "\n",
    "Run to start the tracking server:\n",
    "\n",
    "```mlflow server --backend-store-uri sqlite:///mflow.db --default-artifact-root mlruns/ --host 0.0.0.0 --port 5000```\n",
    "\n",
    "in a terminal. Make sure you run it inside the virtual environment! Put `pipenv run` in front of it.\n",
    "\n",
    "Now you should be able to see the Tracking UI in a browser at `http://0.0.0.0:5000`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a947eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "447b5615",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_server_uri = \"http://127.0.0.1:5000\"   # set to your server URI\n",
    "mlflow.set_tracking_uri(remote_server_uri)  # or set the MLFLOW_TRACKING_URI in the env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36fa3afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://127.0.0.1:5000'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.tracking.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2fd8884-269a-4a1b-8ed2-a6673328e197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e930ea21",
   "metadata": {},
   "source": [
    "### Create a new experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21e087de",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"penguin_classification\"\n",
    "mlflow.create_experiment(exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fc6a11",
   "metadata": {},
   "source": [
    "## 1.5. Add tracking code to the machine learning experiment above\n",
    "\n",
    "Basic things to track:\n",
    "- Parameters: Key-value input parameters: `mlflow.log_param, mlflow.log_params`\n",
    "- Metrics: Key-value metrics, where the value is numeric (can be updated over the run): `mlflow.log_metric, mlflow.log_metrics`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0765bc20",
   "metadata": {},
   "source": [
    "Recall the following code from above:\n",
    "\n",
    "```python\n",
    "# Load dataset\n",
    "culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "target_column = \"Species\"\n",
    "\n",
    "data_path = \"../data/penguins_classification.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Prepare a train-test-split\n",
    "data, target = data[culmen_columns], data[target_column]\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, random_state=0)\n",
    "\n",
    "# Initialize and fit a classifier\n",
    "tree = DecisionTreeClassifier(max_depth=3, max_leaf_nodes=4)\n",
    "tree.fit(data_train, target_train)\n",
    "\n",
    "# Calculate test scores\n",
    "test_score = tree.score(data_test, target_test)\n",
    "print(f\"Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")\n",
    "```\n",
    "\n",
    "\n",
    "Now we add the required code to track the experiment with MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fedeecaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/13 00:56:27 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started run 96e58b1e0f7c425fb2469c8d6d3044fb\n",
      "Load dataset...\n",
      "Prepare a train-test-split...\n",
      "Initialize and fit a DecisionTreeClassifier with max_depth=3, max_leaf_nodes4\n",
      "Result: Accuracy of the DecisionTreeClassifier: 96.5%\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(exp_name)  # <-- set the experiment we want to track to\n",
    "with mlflow.start_run() as run:         # <-- start a run of the experiment\n",
    "    print(f\"Started run {run.info.run_id}\")\n",
    "    # Load dataset\n",
    "    print(\"Load dataset...\")\n",
    "    culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "    target_column = \"Species\"\n",
    "\n",
    "    data_path = \"penguins_classification.csv\"\n",
    "    data = pd.read_csv(data_path)\n",
    "\n",
    "    # Prepare a train-test-split\n",
    "    print(\"Prepare a train-test-split...\")\n",
    "    data, target = data[culmen_columns], data[target_column]\n",
    "    data_train, data_test, target_train, target_test = train_test_split(\n",
    "        data, target, random_state=0)\n",
    "\n",
    "    # Initialize and fit a classifier\n",
    "    max_depth = 3\n",
    "    max_leaf_nodes = 4\n",
    "    print(f\"Initialize and fit a DecisionTreeClassifier with max_depth={max_depth}, max_leaf_nodes{max_leaf_nodes}\")\n",
    "    \n",
    "    mlflow.log_params(            # <-- Track parameters\n",
    "        {\"max_depth\": max_depth, \n",
    "         \"max_leaf_nodes\": max_leaf_nodes}\n",
    "    )\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        max_leaf_nodes=max_leaf_nodes\n",
    "    )\n",
    "    tree.fit(data_train, target_train)\n",
    "\n",
    "    # Calculate test scores\n",
    "    test_score = tree.score(data_test, target_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_score)   # <-- Track metrics\n",
    "    print(f\"Result: Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344a6d30",
   "metadata": {},
   "source": [
    "Have a look at the tracking UI to see how it played out!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b28e17d",
   "metadata": {},
   "source": [
    "## 1.6. Exercise: track some more stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a513541",
   "metadata": {},
   "source": [
    "What else could we want to track?\n",
    "\n",
    "Examples:  \n",
    "- Code Version: Git commit hash used for the run (if it was run from an MLflow Project)\n",
    "- Start & End Time: Start and end time of the run\n",
    "- Source: what code run?\n",
    "- Plots.\n",
    "- Properties of the input data\n",
    "- Model artifacts\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac48edd",
   "metadata": {},
   "source": [
    "### Exercises: \n",
    "- Track the properties of the input data as parameters. (Hint: `data.shape[0]` gives the number of samples in a dataframe)\n",
    "- Track the notebook 'source code'. (Hint: `mlflow.log_artifact()` takes a path and copies the file to the artifact store.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2150c6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started run d00b134904d3412eb5fe710dbcb1b0ad\n",
      "Load dataset...\n",
      "Prepare a train-test-split...\n",
      "Initialize and fit a DecisionTreeClassifier with max_depth=3, max_leaf_nodes4\n",
      "Result: Accuracy of the DecisionTreeClassifier: 96.5%\n"
     ]
    }
   ],
   "source": [
    "# EXERCISE:\n",
    "\n",
    "mlflow.set_experiment(exp_name)  # <-- set the experiment we want to track to\n",
    "with mlflow.start_run() as run:         # <-- start a run of the experiment\n",
    "    print(f\"Started run {run.info.run_id}\")\n",
    "    # Load dataset\n",
    "    print(\"Load dataset...\")\n",
    "    culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "    target_column = \"Species\"\n",
    "\n",
    "    data_path = \"penguins_classification.csv\"\n",
    "    data = pd.read_csv(data_path)\n",
    "\n",
    "    # Prepare a train-test-split\n",
    "    print(\"Prepare a train-test-split...\")\n",
    "    data, target = data[culmen_columns], data[target_column]\n",
    "    data_train, data_test, target_train, target_test = train_test_split(\n",
    "        data, target, random_state=0)\n",
    "\n",
    "    # Initialize and fit a classifier\n",
    "    max_depth = 3\n",
    "    max_leaf_nodes = 4\n",
    "    print(f\"Initialize and fit a DecisionTreeClassifier with max_depth={max_depth}, max_leaf_nodes{max_leaf_nodes}\")\n",
    "    \n",
    "    mlflow.log_params(            # <-- Track parameters\n",
    "        {\"max_depth\": max_depth, \n",
    "         \"max_leaf_nodes\": max_leaf_nodes}\n",
    "    )\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        max_leaf_nodes=max_leaf_nodes\n",
    "    )\n",
    "    tree.fit(data_train, target_train)\n",
    "\n",
    "    # Calculate test scores\n",
    "    test_score = tree.score(data_test, target_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_score)   # <-- Track metrics\n",
    "    print(f\"Result: Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a39f8f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started run 4b59bee1c6c04f4088f97671c29b314b\n",
      "Load dataset...\n",
      "Prepare a train-test-split...\n",
      "Initialize and fit a DecisionTreeClassifier with max_depth=3, max_leaf_nodes4\n",
      "Result: Accuracy of the DecisionTreeClassifier: 96.5%\n"
     ]
    }
   ],
   "source": [
    "# POSSIBLE SOLUTION:\n",
    "\n",
    "mlflow.set_experiment(exp_name)\n",
    "with mlflow.start_run() as run:\n",
    "    print(f\"Started run {run.info.run_id}\")\n",
    "    # Load dataset\n",
    "    print(\"Load dataset...\")\n",
    "    culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "    target_column = \"Species\"\n",
    "\n",
    "    data_path = \"penguins_classification.csv\"\n",
    "    data = pd.read_csv(data_path)\n",
    "    mlflow.log_param(\"num_samples\", data.shape[0])  # <-- ADDED: track the number of samples in the dataset\n",
    "\n",
    "    # Prepare a train-test-split\n",
    "    print(\"Prepare a train-test-split...\")\n",
    "    data, target = data[culmen_columns], data[target_column]\n",
    "    data_train, data_test, target_train, target_test = train_test_split(\n",
    "        data, target, random_state=0)\n",
    "\n",
    "    # Initialize and fit a classifier\n",
    "    max_depth = 3\n",
    "    max_leaf_nodes = 4\n",
    "    print(f\"Initialize and fit a DecisionTreeClassifier with max_depth={max_depth}, max_leaf_nodes{max_leaf_nodes}\")\n",
    "    \n",
    "    mlflow.log_params(\n",
    "        {\"max_depth\": max_depth, \n",
    "         \"max_leaf_nodes\": max_leaf_nodes}\n",
    "    )\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        max_leaf_nodes=max_leaf_nodes\n",
    "    )\n",
    "    tree.fit(data_train, target_train)\n",
    "\n",
    "    # Calculate test scores\n",
    "    test_score = tree.score(data_test, target_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_score)\n",
    "    mlflow.log_artifact(\"1_Run and track experiments.ipynb\")  # <-- ADDED: track the source code of the notebook\n",
    "    print(f\"Result: Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9548fff0",
   "metadata": {},
   "source": [
    "## 1.7. Log the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee84310",
   "metadata": {},
   "source": [
    "We want to store the model artifacts to reuse it for deployment or later experimentation.\n",
    "Since we used a scikit-learn model here, we can use the build-in module to store the model in sklearn format. \n",
    "\n",
    "```mlflow.sklearn.log_model(tree, \"model\")```\n",
    "\n",
    "There are buildin modules for all kind of types of models, as well as the possibility to specify a custom format. Even autologging is available!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98ca2b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started run eebecbfbfb4f4f3d879832354d0bfe9c\n",
      "Load dataset...\n",
      "Prepare a train-test-split...\n",
      "Initialize and fit a DecisionTreeClassifier with max_depth=3, max_leaf_nodes4\n",
      "Result: Accuracy of the DecisionTreeClassifier: 96.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul.qadeer\\Anaconda3\\lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(exp_name)  # <-- set the experiment we want to track to\n",
    "with mlflow.start_run() as run:         # <-- start a run of the experiment\n",
    "    print(f\"Started run {run.info.run_id}\")\n",
    "    # Load dataset\n",
    "    print(\"Load dataset...\")\n",
    "    culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "    target_column = \"Species\"\n",
    "\n",
    "    data_path = \"penguins_classification.csv\"\n",
    "    data = pd.read_csv(data_path)\n",
    "    mlflow.log_param(\"num_samples\", data.shape[0])  # <-- track the number of samples in the dataset\n",
    "\n",
    "    # Prepare a train-test-split\n",
    "    print(\"Prepare a train-test-split...\")\n",
    "    data, target = data[culmen_columns], data[target_column]\n",
    "    data_train, data_test, target_train, target_test = train_test_split(\n",
    "        data, target, random_state=0)\n",
    "\n",
    "    # Initialize and fit a classifier\n",
    "    max_depth = 3\n",
    "    max_leaf_nodes = 4\n",
    "    print(f\"Initialize and fit a DecisionTreeClassifier with max_depth={max_depth}, max_leaf_nodes{max_leaf_nodes}\")\n",
    "    \n",
    "    mlflow.log_params(            # <-- Track parameters\n",
    "        {\"max_depth\": max_depth, \n",
    "         \"max_leaf_nodes\": max_leaf_nodes}\n",
    "    )\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        max_leaf_nodes=max_leaf_nodes\n",
    "    )\n",
    "    tree.fit(data_train, target_train)\n",
    "\n",
    "    # Calculate test scores\n",
    "    test_score = tree.score(data_test, target_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_score)   # <-- Track metrics\n",
    "    print(f\"Result: Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(tree, \"model\")  # <-- Log the model\n",
    "    mlflow.log_artifact(\"1_Run and track experiments.ipynb\")  # <-- track the source code of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4d31206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice: Run the experiment (in the above cell) with different model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcaf369",
   "metadata": {},
   "source": [
    "## 1.8. Compare models in the UI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8461ec0c",
   "metadata": {},
   "source": [
    "## 1.9. Optional: Add a signature to the model\n",
    "\n",
    "Define what the model expects and enforce later in deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd07df45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec\n",
    "\n",
    "input_schema = Schema([\n",
    "  ColSpec(\"double\", \"Culmen Length (mm)\"),\n",
    "  ColSpec(\"double\", \"Culmen Depth (mm)\"),\n",
    "])\n",
    "output_schema = Schema([ColSpec(\"string\")])\n",
    "\n",
    "signature = ModelSignature(inputs=input_schema, outputs=output_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35afcf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started run 2113707cfa16410c8203963b4acb5a93\n",
      "Load dataset...\n",
      "Prepare a train-test-split...\n",
      "Initialize and fit a DecisionTreeClassifier with max_depth=3, max_leaf_nodes4\n",
      "Result: Accuracy of the DecisionTreeClassifier: 96.5%\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(exp_name)\n",
    "with mlflow.start_run() as run:\n",
    "    print(f\"Started run {run.info.run_id}\")\n",
    "    # Load dataset\n",
    "    print(\"Load dataset...\")\n",
    "    culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "    target_column = \"Species\"\n",
    "\n",
    "    data_path = \"penguins_classification.csv\"\n",
    "    data = pd.read_csv(data_path)\n",
    "    mlflow.log_param(\"num_samples\", data.shape[0])\n",
    "\n",
    "    # Prepare a train-test-split\n",
    "    print(\"Prepare a train-test-split...\")\n",
    "    data, target = data[culmen_columns], data[target_column]\n",
    "    data_train, data_test, target_train, target_test = train_test_split(\n",
    "        data, target, random_state=0)\n",
    "\n",
    "    # Initialize and fit a classifier\n",
    "    max_depth = 3\n",
    "    max_leaf_nodes = 4\n",
    "    print(f\"Initialize and fit a DecisionTreeClassifier with max_depth={max_depth}, max_leaf_nodes{max_leaf_nodes}\")\n",
    "    \n",
    "    mlflow.log_params(\n",
    "        {\"max_depth\": max_depth, \n",
    "         \"max_leaf_nodes\": max_leaf_nodes}\n",
    "    )\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        max_leaf_nodes=max_leaf_nodes\n",
    "    )\n",
    "    tree.fit(data_train, target_train)\n",
    "\n",
    "    # Calculate test scores\n",
    "    test_score = tree.score(data_test, target_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_score)\n",
    "    print(f\"Result: Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(tree, \"model\", signature=signature)  # <-- Now log the model with a signature\n",
    "    mlflow.log_artifact(\"1_Run and track experiments.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8b7642",
   "metadata": {},
   "source": [
    "## 1.10. Use the model to predict locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9550aa26",
   "metadata": {},
   "source": [
    "Now we pick a model, retrieve it and make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70f86ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Adelie', 'Chinstrap', 'Adelie', 'Chinstrap', 'Adelie',\n",
       "       'Chinstrap', 'Gentoo', 'Adelie', 'Gentoo', 'Adelie', 'Adelie',\n",
       "       'Gentoo', 'Gentoo', 'Adelie', 'Adelie', 'Gentoo', 'Gentoo',\n",
       "       'Gentoo', 'Chinstrap', 'Adelie', 'Chinstrap', 'Adelie',\n",
       "       'Chinstrap', 'Gentoo', 'Adelie', 'Adelie', 'Gentoo', 'Chinstrap',\n",
       "       'Gentoo', 'Gentoo', 'Adelie', 'Adelie', 'Adelie', 'Gentoo',\n",
       "       'Gentoo', 'Adelie', 'Chinstrap', 'Gentoo', 'Chinstrap', 'Adelie',\n",
       "       'Adelie', 'Adelie', 'Adelie', 'Gentoo', 'Adelie', 'Adelie',\n",
       "       'Chinstrap', 'Gentoo', 'Gentoo', 'Chinstrap', 'Adelie', 'Adelie',\n",
       "       'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Gentoo', 'Adelie',\n",
       "       'Adelie', 'Chinstrap', 'Adelie', 'Adelie', 'Adelie', 'Gentoo',\n",
       "       'Adelie', 'Adelie', 'Adelie', 'Gentoo', 'Adelie', 'Gentoo',\n",
       "       'Adelie', 'Chinstrap', 'Adelie', 'Adelie', 'Gentoo', 'Adelie',\n",
       "       'Chinstrap', 'Adelie', 'Adelie', 'Gentoo', 'Adelie', 'Gentoo',\n",
       "       'Chinstrap', 'Adelie', 'Chinstrap', 'Gentoo'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logged_model = 'runs:/2113707cfa16410c8203963b4acb5a93/model'\n",
    "\n",
    "# Load model as a Sklearn Model.\n",
    "loaded_model = mlflow.sklearn.load_model(logged_model)\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "loaded_model.predict(pd.DataFrame(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb548c5-2ea5-403f-97c5-d197c39ec6b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301bc47b-634a-407d-b04a-0d391483ecc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
